hydra:
  job:
    chdir: false
batch_size: 1
model_name: "model/Mixtral-8x7B-Instruct-v0.1"
rand_seed: 1
task_name: scinli
rerank_method: random  # human/random/mixtral
output_file: output/pred_data/${task_name}/mixtral/manual_${rerank_method}_seed${rand_seed}_bs${batch_size}.json  # llama2-70b/mixtral
sample_num: 5
max_new_token: 258
window: 10
span: true
n_tokens: 700
instruction_template: 1
overwrite: true
calibrate: false
reverse_label: false
prior_no: 1
dataset_reader:
  _target_: src.dataset_readers.ppl_inference_cls_dsr.PPLCLSInferenceDatasetReader
  dataset_path: output/retrived_data/${task_name}/retrieved_topk.json
  task_name: ${task_name}
  model_name: ${model_name}
  index_split: "train"
  n_tokens: 700
  index_data_path: null
model:
  _target_: transformers.AutoModelForCausalLM.from_pretrained
  pretrained_model_name_or_path: ${model_name}
